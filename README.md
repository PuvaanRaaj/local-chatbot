# LLM Chatbot (Code Review, Generation, Debugging, and More)

This project is a lightweight, developer-friendly chatbot powered by **Docker Model Runner** (e.g. LLaMA 3.2 or other local models), styled like ChatGPT, with support for:

* **Code Review**
* **Code Generation**
* **General Q\&A**
* **Debugging**
* **Optimization**

It runs fully locally via **Docker + Flask**, with markdown rendering, streaming response, copy buttons, and multiple modes.

---

## Features

* Dark-mode responsive UI with Tailwind
* Markdown + code block rendering
* Upload file support (+ icon)
* Streamed assistant typing effect
* Multiple endpoints and prompts (review, generate, debug...)
* Runs entirely on Docker (LLM + app)

---

## Project Structure

```
llm-chatbot/
â”œâ”€â”€ app.py                # Flask entry
â”œâ”€â”€ routes/              # Route handlers
â”‚   â””â”€â”€ chat_routes.py
â”œâ”€â”€ services/            # Chat logic
â”‚   â””â”€â”€ llama_runner.py
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html       # Mode selector
â”‚   â””â”€â”€ chat.html        # Chat UI
â”œâ”€â”€ .env                 # Copied from .env.example
â”œâ”€â”€ .env.example         # Sample environment file
â”œâ”€â”€ requirements.txt
â””â”€â”€ demo/
    â””â”€â”€ <your-screenshots-here>.png
```

---

## Getting Started

### 1. Prerequisites

* Docker Desktop
* Docker Model Runner plugin

### 2. Clone This Repo

```bash
git clone https://github.com/yourname/llm-chatbot
cd llm-chatbot
cp .env.example .env
```

### 3. Install Docker Model Runner (Only Once)

```bash
docker extension install docker/model:latest
```

Then enable TCP support:

```bash
docker model install-runner --tcp 12434
```

Or in Docker Desktop:

1. Go to **Settings > Features in Development**
2. Enable **Model Runner TCP support**

![Docker Model Runner Enable](demo/docker-model-runner-enable.png)

### 4. Pull Your Model

```bash
docker model pull ai/llama3.2:latest
```

You may use any compatible model such as `ai/qwen3:latest`, `llama3.3:latest`, or  `unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF`.

---

## ðŸ›  Run It (Local Dev)

Use Docker to start the chatbot container:

```bash
docker compose up -d
```

Then visit: [http://localhost:12345](http://localhost:12345)

---

## ðŸ”§ .env

Copy it:

```bash
cp .env.example .env
```

---

## ðŸ“„ requirements.txt

```txt
flask
requests
python-dotenv
```

---

## âœ… Features to Explore

* [ ] Add Chat History (localStorage?)
* [ ] Auth or Login (JWT, sessions)
* [ ] Save/Share prompts

---

## ðŸ§  Credits

* Powered by Docker Model Runner

---

## ðŸ“œ License

MIT. Use freely. Attribution appreciated.
